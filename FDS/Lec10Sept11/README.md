# Lecture 10

- [Lecture 10](#lecture-10)
  - [Video](#video)
  - [PCA](#pca)
  - [SVD](#svd)

## Video

[link](https://drive.google.com/file/d/1mxnjdoizboe8pVDFHtOlFhWY_B3GR0n-/view)

## PCA

![pca](pca.png)

![pc](pca2.png)

## SVD

- produces same new axes as PCA

![svd](svd1.png)

![s](s2.png)

- when I try to reduce some dimensions, I loose some information
- we need to minimize that loss, that's what we do by removing least variance data

- PCA is unsupervised
- PCA is not good for labelled data - class labels wale, bcz overlap aa jayega

![pcang](pcang.png)

![s2](s4.png)

- best fit ke perpendicular line
- so 2nd best

![s5](s5.png)

![s6](s6.png)

![s](s7.png)

![s](s8.png)

![s](s9.png)

![s](s10.png)

![s](s11.png)

![s](s12.png)